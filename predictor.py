# -*- coding: utf-8 -*-
"""Predictor.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/158fa9ltu69JuB7xedxEdmT7xAeYTGemi
"""

import tensorflow as tf
import keras
from keras.models import load_model
import seaborn as sns
import pandas as pd
import matplotlib.pyplot as plt

from google.colab import drive
drive.mount('/content/drive')

image_size = (256,256)
class_names = [ 'meningioma','glioma', 'pituitary']

model = load_model('/content/drive/MyDrive/Colab Notebooks/model_final_multi-classification.h5')

img = keras.preprocessing.image.load_img(
    "/content/drive/MyDrive/Colab Notebooks/dataset/yes/y1179.jpg", 
    target_size=image_size
)
img_array = keras.preprocessing.image.img_to_array(img)
img_array = tf.expand_dims(img_array, 0)  # Create batch axis
predictions = model.predict(img_array)
score = predictions[0]
print(score)

batch = 32

test = tf.keras.preprocessing.image_dataset_from_directory(
        "/content/drive/MyDrive/Colab Notebooks/dataset/Testing",
            seed = 42,
            
            batch_size = batch)

test = test.prefetch(buffer_size=32)

import numpy as np
img = keras.preprocessing.image.load_img(
    "/content/drive/MyDrive/Colab Notebooks/dataset/BrainTumor/meningioma/101.jpg", 
    target_size=image_size
    )
img_array = keras.preprocessing.image.img_to_array(img)
img_array = tf.expand_dims(img_array, 0)  # Create batch axis

predictions = np.argmax(model.predict(img_array))
print(class_names[predictions])

results = model.evaluate(test)
print("test loss, test acc:", results)

labels_entire = []
pred_entire = []
for image_batch,label_batch in test.as_numpy_iterator():
    prediction = model.predict_on_batch(image_batch).flatten()

    # Apply a sigmoid since our model returns logits
    predictions = tf.nn.sigmoid(prediction).numpy()

    n = 0
    predict = []
    while n<=(predictions.shape[0]-3):
        pred = np.argmax(predictions[n:n+3]) #Returns the index of the largest element in the selected subarray
        n+=3
        pred_entire.append(pred)
    for el in label_batch:
        labels_entire.append(el)
pred_entire = np.array(pred_entire)
labels_entire = np.array(labels_entire)
print(pred_entire)
print(labels_entire)

from sklearn.metrics import classification_report, multilabel_confusion_matrix
print(classification_report(labels_entire, pred_entire, target_names=class_names))

from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score
print(f"Accuracy: {round(accuracy_score(labels_entire, pred_entire), 2)}")

#print(f"Precision: {round(precision_score(labels_entire, pred_entire), 2)}")
#print(f"Recall: {round(recall_score(labels_entire, pred_entire), 2)}")
#print(f"F1_score: {round(f1_score(labels_entire, pred_entire), 2)}")

from sklearn.metrics import confusion_matrix

arr = confusion_matrix(labels_entire, pred_entire)
df_cm = pd.DataFrame(arr, class_names, class_names)
plt.figure(figsize = (9,6))
sns.heatmap(df_cm, annot=True, fmt="d", cmap='viridis')
plt.xlabel("Prediction")
plt.ylabel("Target")
plt.show()